{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Analysis of the Haunted Places Dataset <center> </h1>\n",
    "\n",
    "<b> Team 3 </b> <br>\n",
    "Members: \n",
    "\n",
    "- Zili Yang\n",
    "- Chen Yi Weng\n",
    "- Aadarsh Sudhir Ghiya \n",
    "- Colin Leahey\n",
    "- Niromikha Jayakumar \n",
    "- Yung Yee Chia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook explores the Haunted Places dataset, extracts new features, joins additional datasets, and analyzes the data using similarity metrics and clustering techniques. The tasks include:\n",
    "1. Preprocessing the dataset.\n",
    "2. Extracting new features from descriptions.\n",
    "3. Joining external datasets.\n",
    "4. Analyzing the combined dataset using Tika-Similarity.\n",
    "5. Visualizing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and install Apache Tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: setuptools in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from tika) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from tika) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from requests->tika) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from requests->tika) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from requests->tika) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from requests->tika) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: number-parser in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (0.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from number-parser) (20.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install number-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datefinder in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (0.7.3)\n",
      "Requirement already satisfied: regex>=2017.02.08 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from datefinder) (2023.5.5)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from datefinder) (2.8.1)\n",
      "Requirement already satisfied: pytz in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from datefinder) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/niromikha/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.4.2->datefinder) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datefinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download the Haunted Places dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "haunted_places_df = pd.read_csv('../Data/haunted_places.csv')\n",
    "\n",
    "# Make a copy of the original dataset\n",
    "haunted_places_copy = haunted_places_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create a combined TSV file for your Haunted Places dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the original CSV file to TSV\n",
    "haunted_places_df = pd.read_csv(\"../Data/haunted_places.csv\")\n",
    "haunted_places_df.to_csv(\"haunted_places.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TSV file for further processing\n",
    "haunted_places = pd.read_csv(\"haunted_places.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. a) Audio Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_audio_evidence(description):\n",
    "    audio_keywords = [\"noises\", \"sound of snapping neck\", \"nursery rhymes\"]\n",
    "    return any(re.search(rf'\\b{keyword}\\b', description, re.IGNORECASE) for keyword in audio_keywords)\n",
    "\n",
    "haunted_places['Audio Evidence'] = haunted_places['description'].apply(has_audio_evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. b) Image/Video/Visual Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_visual_evidence(description):\n",
    "    visual_keywords = [\"cameras\", \"take pictures\", \"names of children written on walls\"]\n",
    "    return any(re.search(rf'\\b{keyword}\\b', description, re.IGNORECASE) for keyword in visual_keywords)\n",
    "\n",
    "haunted_places['Image/Video/Visual Evidence'] = haunted_places['description'].apply(has_visual_evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. c) Haunted Places Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datefinder\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "def extract_date(description):\n",
    "    try:\n",
    "        # Attempt to find dates in the description\n",
    "        matches = datefinder.find_dates(description)\n",
    "        \n",
    "        # Extract the first valid date\n",
    "        for match in matches:\n",
    "            return match.date()  # Return only the date part\n",
    "        \n",
    "    except Exception:\n",
    "        # Silently handle errors without printing messages\n",
    "        pass\n",
    "    \n",
    "    # Fallback to '2025-01-01' if no valid date is found or an error occurs\n",
    "    return datetime.date(2025, 1, 1)\n",
    "\n",
    "# Apply the function to the 'description' column\n",
    "haunted_places['Haunted Places Date'] = haunted_places['description'].apply(extract_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2025-02-03\n",
       "1        2025-02-01\n",
       "2        2025-01-01\n",
       "3        0211-02-27\n",
       "4        2025-01-01\n",
       "            ...    \n",
       "10987    2025-02-12\n",
       "10988    2025-01-01\n",
       "10989    2025-02-18\n",
       "10990    2025-01-01\n",
       "10991    2025-01-01\n",
       "Name: Haunted Places Date, Length: 10992, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haunted_places['Haunted Places Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. d) Haunted Places Witness Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             description  \\\n",
      "0      Ada witch - Sometimes you can see a misty blue...   \n",
      "1      A little girl was killed suddenly while waitin...   \n",
      "2      If you take Gorman Rd. west towards Sand Creek...   \n",
      "3      In the 1970's, one room, room 211, in the old ...   \n",
      "4      Kappa Delta Sorority - The Kappa Delta Sororit...   \n",
      "...                                                  ...   \n",
      "10987  at 12 midnight you can see a lady with two lit...   \n",
      "10988  Is haunted by the victims of a murder that hap...   \n",
      "10989  The institution was for kids 18 years old and ...   \n",
      "10990  Gymnasium -  their have been reports of a litt...   \n",
      "10991  Cadets from the Air Force Academy participatin...   \n",
      "\n",
      "       Haunted Places Witness Count  \n",
      "0                                 0  \n",
      "1                                 0  \n",
      "2                                 0  \n",
      "3                                 2  \n",
      "4                                 0  \n",
      "...                             ...  \n",
      "10987                             2  \n",
      "10988                             0  \n",
      "10989                             0  \n",
      "10990                             0  \n",
      "10991                             0  \n",
      "\n",
      "[10992 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from number_parser import parse_number\n",
    "\n",
    "def preprocess_description(description):\n",
    "    \"\"\"Replace vague phrases with estimated numbers to aid extraction.\"\"\"\n",
    "    description = description.lower()\n",
    "    # Replace ambiguous phrases with approximate numbers\n",
    "    replacements = {\n",
    "        \"some\": \"3\",\n",
    "        \"a few\": \"3\",\n",
    "        \"several\": \"5\",\n",
    "        \"many\": \"10\",\n",
    "        \"a lot\": \"10\",\n",
    "        \"a handful\": \"5\",\n",
    "        \"numerous\": \"10\",\n",
    "        \"countless\": \"15\",\n",
    "        \"dozens\": \"12\",\n",
    "        \"scores\": \"20\",\n",
    "        \"hundreds\": \"100\",\n",
    "        \"a couple\": \"2\"\n",
    "    }\n",
    "    \n",
    "    for word, num in replacements.items():\n",
    "        description = re.sub(rf\"\\b{word}\\b\", num, description)  # Whole-word replacement\n",
    "    return description\n",
    "\n",
    "\n",
    "def extract_numbers_from_text(text):\n",
    "    \"\"\"Extract numerical values from written-out numbers in the text.\"\"\"\n",
    "    # Define a regex pattern to match written-out numbers\n",
    "    number_words = r'\\b(?:zero|one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|thirteen|fourteen|fifteen|sixteen|seventeen|eighteen|nineteen|twenty|thirty|forty|fifty|sixty|seventy|eighty|ninety|hundred|thousand|million|billion)\\b'\n",
    "    \n",
    "    # Find all matches of written-out numbers\n",
    "    matches = re.findall(number_words, text.lower())\n",
    "    \n",
    "    # Parse each match into a numerical value\n",
    "    numbers = [parse_number(match) for match in matches if parse_number(match) is not None]\n",
    "    \n",
    "    # Filter out irrelevant numbers (e.g., years, small numbers)\n",
    "    filtered_numbers = [num for num in numbers if not (1900 <= num <= 2100)]  # Remove years\n",
    "    filtered_numbers = [num for num in filtered_numbers if num > 1]  # Ignore small numbers\n",
    "    \n",
    "    return filtered_numbers\n",
    "\n",
    "\n",
    "def extract_witness_count(description):\n",
    "    \"\"\"\n",
    "    Extract witness count from a haunted place description.\n",
    "    Returns a tuple (witness_count, method) where method indicates how the count was derived.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Preprocess the description\n",
    "        preprocessed_text = preprocess_description(description)\n",
    "        \n",
    "        # Step 2: Extract numbers from the text\n",
    "        numbers = extract_numbers_from_text(preprocessed_text)\n",
    "        \n",
    "        # Step 3: Return the first valid number found, or 0 if no numbers are found\n",
    "        if numbers:\n",
    "            return numbers[0], \"explicit_number\"\n",
    "        \n",
    "        # Step 4: Default to 0 if no numbers are found\n",
    "        return 0, \"default\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing witness count from description: {description[:100]}... Error: {e}\")\n",
    "        return 0, \"error\"\n",
    "\n",
    "\n",
    "# Apply the function to the 'description' column\n",
    "haunted_places['Haunted Places Witness Count'] = haunted_places['description'].apply(\n",
    "    lambda desc: extract_witness_count(desc)[0]  # Extract only the count (not the method)\n",
    ")\n",
    "\n",
    "# Display the updated columns\n",
    "print(haunted_places[['description', 'Haunted Places Witness Count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. e) Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time_of_day(description):\n",
    "    time_keywords = {\"evening\": \"Evening\", \"morning\": \"Morning\", \"dusk\": \"Dusk\"}\n",
    "    for keyword, time_of_day in time_keywords.items():\n",
    "        if re.search(rf'\\b{keyword}\\b', description, re.IGNORECASE):\n",
    "            return time_of_day\n",
    "    return \"Unknown\"\n",
    "\n",
    "haunted_places['Time of Day'] = haunted_places['description'].apply(extract_time_of_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. f) Apparition Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_apparition_type(description):\n",
    "    apparition_keywords = {\n",
    "        \"ghost\": \"Ghost\",\n",
    "        \"orb\": \"Orb\",\n",
    "        \"ufo\": \"UFO\",\n",
    "        \"uap\": \"UAP\",\n",
    "        \"male\": \"Male\",\n",
    "        \"female\": \"Female\",\n",
    "        \"child\": \"Child\",\n",
    "        \"several ghosts\": \"Several Ghosts\"\n",
    "    }\n",
    "    for keyword, apparition_type in apparition_keywords.items():\n",
    "        if re.search(rf'\\b{keyword}\\b', description, re.IGNORECASE):\n",
    "            return apparition_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "haunted_places['Apparition Type'] = haunted_places['description'].apply(extract_apparition_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. g) Event type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_type(description):\n",
    "    event_keywords = {\n",
    "        \"murder\": \"Murder\",\n",
    "        \"die\": \"Death\",\n",
    "        \"supernatural\": \"Supernatural Phenomenon\"\n",
    "    }\n",
    "    for keyword, event_type in event_keywords.items():\n",
    "        if re.search(rf'\\b{keyword}\\b', description, re.IGNORECASE):\n",
    "            return event_type\n",
    "    return \"Unknown\"\n",
    "\n",
    "haunted_places['Event Type'] = haunted_places['description'].apply(extract_event_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city        country  \\\n",
      "1520     Lenox  United States   \n",
      "3394  Woodward  United States   \n",
      "8524     Paris  United States   \n",
      "\n",
      "                                            description  \\\n",
      "1520  An eleven year old girl, whose last name is Sl...   \n",
      "3394  This coffee house was originally a doctor's of...   \n",
      "8524  Most people get a bad feeling just looking at ...   \n",
      "\n",
      "                                 location          state state_abbrev  \\\n",
      "1520                     Cranewell Resort  Massachusetts           MA   \n",
      "3394                     Leos Coffeehouse       Oklahoma           OK   \n",
      "8524  Old Plantation home in Slate Shoals          Texas           TX   \n",
      "\n",
      "      longitude   latitude  city_longitude  city_latitude  Audio Evidence  \\\n",
      "1520 -73.267236  42.341822      -73.284876      42.356461           False   \n",
      "3394 -99.393019  36.434108      -99.390386      36.433648           False   \n",
      "8524        NaN        NaN      -95.555513      33.660939           False   \n",
      "\n",
      "      Image/Video/Visual Evidence Haunted Places Date  \\\n",
      "1520                        False          2025-01-01   \n",
      "3394                        False          2025-01-01   \n",
      "8524                        False          2025-05-27   \n",
      "\n",
      "      Haunted Places Witness Count Time of Day Apparition Type Event Type  \n",
      "1520                            11     Unknown         Unknown    Unknown  \n",
      "3394                            11     Unknown         Unknown    Unknown  \n",
      "8524                            11     Unknown         Unknown    Unknown  \n"
     ]
    }
   ],
   "source": [
    "#to check\n",
    "visual_evidence_records = haunted_places[haunted_places['Haunted Places Witness Count'] == 11]\n",
    "\n",
    "# Display the filtered records\n",
    "print(visual_evidence_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4h) Merge the Alcohol Abuse Dataset\n",
    "\n",
    "This cell loads the Haunted Places dataset and the Alcohol Abuse dataset (downloaded from [drugabusestatistics.org/alcohol](https://drugabusestatistics.org/alcohol)),\n",
    "merges them on the 'State' column, and saves the merged dataset as a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_alcohol_data(haunted_path, alcohol_path, output_path):\n",
    "    \"\"\"\n",
    "    Merges the Haunted Places dataset with the Alcohol Abuse dataset on 'State'.\n",
    "    \"\"\"\n",
    "    # Load the Haunted Places dataset\n",
    "    haunted_df = pd.read_csv(haunted_path)\n",
    "\n",
    "    # Load the Alcohol Abuse dataset\n",
    "    alcohol_df = pd.read_csv(alcohol_path)\n",
    "\n",
    "    # Merge on 'State' using a left join\n",
    "    merged_df = pd.merge(haunted_df, alcohol_df, on=\"State\", how=\"left\")\n",
    "\n",
    "    # Save the merged dataset\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f\"Merged dataset saved to {output_path}\")\n",
    "\n",
    "# Example usage: adjust file paths as needed\n",
    "merge_alcohol_data(\n",
    "    haunted_path = \"haunted_places.csv\",    # Path to your Haunted Places dataset\n",
    "    alcohol_path = \"alcohol_abuse.csv\",       # Path to the Alcohol Abuse dataset\n",
    "    output_path = \"haunted_places_with_alcohol.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
